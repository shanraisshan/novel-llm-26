# Previous Research Summary for Iteration 24

## Best Results So Far
- **Iteration 13 (20% consensus)**: "Is your answer to this question exactly one word long? Answer yes or no." - Boolean self-reference (BUT user rejected self-referential questions)
- **Iteration 12 (40% consensus)**: "How many words are in your answer to this question?" - Self-referential output counting (BUT user rejected)

## Key Insights from 23 Iterations

### What FAILS (100% Consensus - Dead Ends):
1. Letter counting with semantic primes
2. Position tracking
3. Explicit modifications to classic puzzles
4. Override conditions
5. Unit mismatches
6. Classic cognitive traps
7. Last digit arithmetic
8. Simple circular spatial reasoning
9. Physical world intuition with implicit context
10. Irrelevant information traps
11. Reasoning delirium / overthinking with explicit answers
12. Age gap riddles with semantic primes
13. **False presupposition rejection for basic math (iteration 23)** - "What whole number is between 3 and 4?" = 100% correct "no such number"

### Partial Success (80% Consensus):
- Relational reasoning with siblings (iteration 6)
- Contradiction detection (iteration 8)

### Critical Observation After 23 Iterations

**EVERY single approach tried has resulted in 100% consensus** (except self-referential which is banned and iterations 6, 8 with 80%).

This suggests:
1. 2026 frontier models are EXTREMELY robust
2. All documented failure modes from research are now patched
3. All famous riddles/puzzles are in training data
4. Simple semantic primes don't work
5. Simple false presuppositions don't work
6. Simple implicit inferences work correctly

## What MIGHT Work (Unexplored)

### TRULY NOVEL - Not In Any Research:
1. **Garden path sentences** - Sentences where initial parsing is wrong
2. **Scope ambiguity** - "Every man loves some woman" (universal vs existential)
3. **Questions requiring world knowledge gaps** - Facts not in training
4. **Novel linguistic constructions** - Never-before-seen sentence patterns
5. **Cross-linguistic interference** - Loan words, false friends
6. **Pragmatic scalar implicature** - "Some students passed" implies "not all"

### MUST AVOID:
- Self-referential (banned)
- Any famous riddle/puzzle
- Any documented failure mode
- Simple math impossibilities
- Simple semantic primes
- Anything that's appeared on Reddit, TikTok, research papers

## The Core Challenge

After 23 iterations, it's clear that finding a question that:
- Has ONE correct answer
- Humans find trivially easy
- LLMs consistently fail
- Is NOT self-referential

...is EXTREMELY difficult with 2026 frontier models.

The only success (iteration 13, 20%) was self-referential - now banned.
